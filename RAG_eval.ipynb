{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9bff53e",
   "metadata": {},
   "source": [
    "# Lesson 1: Advanced RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feb98470-c136-471d-a63e-d50d8eb09c57",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = utils.get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31e2859b-596e-40b3-867b-f4d6e91f74bc",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./data\").load_data()\n",
    "#    input_files=[\"./eBook-How-to-Build-a-Career-in-AI.pdf\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d7d0857-b9d1-4feb-8243-bfd2f4953acd",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "87 \n",
      "\n",
      "<class 'llama_index.schema.Document'>\n",
      "Doc ID: 76fc43f9-2cc0-418e-b8f0-73ab2efbfd70\n",
      "Text: 事務連絡  平成２５年４月 １５日    各都道府県衛生主管部（局）薬務主管課 御中       厚生労働省医薬食品局審査管理課\n",
      "細胞・組織加工医薬品等の製造に関連するものに係る原薬等登録原簿 登録申請書及びその申請書に添付すべき資料の作成要領に関する Q&A について\n",
      "「細胞・組織加工医薬品等の製造に関連するものに係る原薬等登録原簿、 登 録申請書及びその申請書に添付すべき資料の作成要領」\n",
      "については、平成２５ 年３月８日付け事務連絡により示したところですが、今般、質疑応答集を別添のとおりまとめましたので、貴管内関係者に対し周知\n",
      "方よろしく御配慮をお願いします。\n"
     ]
    }
   ],
   "source": [
    "print(type(documents), \"\\n\")\n",
    "print(len(documents), \"\\n\")\n",
    "print(type(documents[0]))\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3123d3d",
   "metadata": {},
   "source": [
    "## Basic RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4abc806-64f5-46bb-8c9f-6469ecb18d20",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afc2baff-5e8b-4733-9899-16f248777b23",
   "metadata": {
    "height": 183,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17550a39f73549a6be0f0a052082ed45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555d96e5cc7c4ed8a7954febd1fe3214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074328cbe63f43c6bb05a778dec3c70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3acf9d490f2e47c29d22002ed0127346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7373d0a3d905453b80f2f9eac7b49c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a8c0f606444808806b708f6d4a76c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /tmp/llama_index...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, embed_model=\"local:BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "index = VectorStoreIndex.from_documents([document],\n",
    "                                        service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae52a26c-7d0c-44df-8043-4c7f19f794b9",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b0d5b6e-cc2e-4648-b28c-5fa25a97d175",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFは、登録事項の変更や承継に関連する医薬品のマスターファイル（Master File）の略称です。\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"MFとはなんですか?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50a1ac5",
   "metadata": {},
   "source": [
    "## Evaluation setup using TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ead7dc1-71b2-4001-918f-bf8d610fd3fd",
   "metadata": {
    "height": 132,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFとはなんですか。日本語で答えてください。\n",
      "MFの申請書類はなんですか。日本語で答えてください。\n",
      "USPに登録がる原薬をMFに登録する際の注意点はなんですか。日本語で答えてください。\n",
      "MFの仕組みを教えてください。日本語で答えてください。\n"
     ]
    }
   ],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a278f8",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# You can try your own question:\n",
    "new_question = \"What is the right AI job for me?\"\n",
    "eval_questions.append(new_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d771b303",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d5204e8",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(eval_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c063c9c7-bf1e-4b24-9a22-d4281c0f954e",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦑 Tru initialized with db url sqlite:///default.sqlite .\n",
      "🛑 Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "tru = Tru()\n",
    "\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03802825-6ce4-4563-aeec-d8d57e095ad1",
   "metadata": {},
   "source": [
    "For the classroom, we've written some of the code in helper functions inside a utils.py file.  \n",
    "- You can view the utils.py file in the file directory by clicking on the \"Jupyter\" logo at the top of the notebook.\n",
    "- In later lessons, you'll get to work directly with the code that's currently wrapped inside these helper functions, to give you more options to customize your RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f754bed-d16f-4c8d-a1a1-b36096272570",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_prebuilt_trulens_recorder\n",
    "\n",
    "tru_recorder = get_prebuilt_trulens_recorder(query_engine,\n",
    "                                             app_id=\"Direct Query Engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dbdfbcc-aac7-4805-9894-4fc016c66bf6",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tru_recorder as recording:\n",
    "    for question in eval_questions:\n",
    "        response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e14f512b-601c-42d0-bfac-bf41d9c577e7",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2da4a602-0d56-4bf8-9fa6-03ef0b7e254b",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_19a60c2e4f59a43b2b47a2b9920bbc36</td>\n",
       "      <td>\"MF\\u3068\\u306f\\u306a\\u3093\\u3067\\u3059\\u304b\\...</td>\n",
       "      <td>\"MF\\u306f\\u300c\\u539f\\u85ac\\u7b49\\u767b\\u9332\\...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_19a60c2e4f59a43b2b4...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-06-20T22:41:07.178819\", \"...</td>\n",
       "      <td>2024-06-20T22:41:08.317577</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>[{'args': {'prompt': 'MFとはなんですか。日本語で答えてください。',...</td>\n",
       "      <td>[{'args': {'prompt': 'MFとはなんですか。日本語で答えてください。',...</td>\n",
       "      <td>1</td>\n",
       "      <td>2074</td>\n",
       "      <td>0.003122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_75405ab6fa18d38f3eb5a7b478bf8728</td>\n",
       "      <td>\"MF\\u306e\\u7533\\u8acb\\u66f8\\u985e\\u306f\\u306a\\...</td>\n",
       "      <td>\"MF\\u306e\\u7533\\u8acb\\u66f8\\u985e\\u306f\\u3001\\...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_75405ab6fa18d38f3eb...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-06-20T22:41:08.498149\", \"...</td>\n",
       "      <td>2024-06-20T22:41:10.207188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[{'args': {'prompt': 'MFの申請書類はなんですか。日本語で答えてくださ...</td>\n",
       "      <td>[{'args': {'prompt': 'MFの申請書類はなんですか。日本語で答えてくださ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1940</td>\n",
       "      <td>0.002938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_aba8da3dc93433af963f7478c748c9d4</td>\n",
       "      <td>\"USP\\u306b\\u767b\\u9332\\u304c\\u308b\\u539f\\u85ac...</td>\n",
       "      <td>\"\\u539f\\u85ac\\u306e\\u6b8b\\u7559\\u6eb6\\u5a92\\u3...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_aba8da3dc93433af963...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-06-20T22:41:10.374231\", \"...</td>\n",
       "      <td>2024-06-20T22:41:14.453109</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[{'args': {'prompt': 'USPに登録がる原薬をMFに登録する際の注意点は...</td>\n",
       "      <td>[{'args': {'prompt': 'USPに登録がる原薬をMFに登録する際の注意点は...</td>\n",
       "      <td>4</td>\n",
       "      <td>2235</td>\n",
       "      <td>0.003453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_4055214a132a80ad4bd223060703a338</td>\n",
       "      <td>\"MF\\u306e\\u4ed5\\u7d44\\u307f\\u3092\\u6559\\u3048\\...</td>\n",
       "      <td>\"MF\\u767b\\u9332\\u8005\\u306f\\u3001\\u533b\\u85ac\\...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_4055214a132a80ad4bd...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-06-20T22:41:14.616523\", \"...</td>\n",
       "      <td>2024-06-20T22:41:18.176021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.003138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                app_id                                           app_json  \\\n",
       "0  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "1  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "2  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "3  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "1  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "2  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "3  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_19a60c2e4f59a43b2b47a2b9920bbc36   \n",
       "1  record_hash_75405ab6fa18d38f3eb5a7b478bf8728   \n",
       "2  record_hash_aba8da3dc93433af963f7478c748c9d4   \n",
       "3  record_hash_4055214a132a80ad4bd223060703a338   \n",
       "\n",
       "                                               input  \\\n",
       "0  \"MF\\u3068\\u306f\\u306a\\u3093\\u3067\\u3059\\u304b\\...   \n",
       "1  \"MF\\u306e\\u7533\\u8acb\\u66f8\\u985e\\u306f\\u306a\\...   \n",
       "2  \"USP\\u306b\\u767b\\u9332\\u304c\\u308b\\u539f\\u85ac...   \n",
       "3  \"MF\\u306e\\u4ed5\\u7d44\\u307f\\u3092\\u6559\\u3048\\...   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"MF\\u306f\\u300c\\u539f\\u85ac\\u7b49\\u767b\\u9332\\...    -   \n",
       "1  \"MF\\u306e\\u7533\\u8acb\\u66f8\\u985e\\u306f\\u3001\\...    -   \n",
       "2  \"\\u539f\\u85ac\\u306e\\u6b8b\\u7559\\u6eb6\\u5a92\\u3...    -   \n",
       "3  \"MF\\u767b\\u9332\\u8005\\u306f\\u3001\\u533b\\u85ac\\...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_19a60c2e4f59a43b2b4...   \n",
       "1  {\"record_id\": \"record_hash_75405ab6fa18d38f3eb...   \n",
       "2  {\"record_id\": \"record_hash_aba8da3dc93433af963...   \n",
       "3  {\"record_id\": \"record_hash_4055214a132a80ad4bd...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "1  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "2  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "3  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2024-06-20T22:41:07.178819\", \"...   \n",
       "1  {\"start_time\": \"2024-06-20T22:41:08.498149\", \"...   \n",
       "2  {\"start_time\": \"2024-06-20T22:41:10.374231\", \"...   \n",
       "3  {\"start_time\": \"2024-06-20T22:41:14.616523\", \"...   \n",
       "\n",
       "                           ts  Answer Relevance  Context Relevance  \\\n",
       "0  2024-06-20T22:41:08.317577               1.0               0.45   \n",
       "1  2024-06-20T22:41:10.207188               1.0               0.50   \n",
       "2  2024-06-20T22:41:14.453109               1.0               1.00   \n",
       "3  2024-06-20T22:41:18.176021               NaN                NaN   \n",
       "\n",
       "                              Answer Relevance_calls  \\\n",
       "0  [{'args': {'prompt': 'MFとはなんですか。日本語で答えてください。',...   \n",
       "1  [{'args': {'prompt': 'MFの申請書類はなんですか。日本語で答えてくださ...   \n",
       "2  [{'args': {'prompt': 'USPに登録がる原薬をMFに登録する際の注意点は...   \n",
       "3                                                NaN   \n",
       "\n",
       "                             Context Relevance_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'prompt': 'MFとはなんですか。日本語で答えてください。',...        1          2074   \n",
       "1  [{'args': {'prompt': 'MFの申請書類はなんですか。日本語で答えてくださ...        1          1940   \n",
       "2  [{'args': {'prompt': 'USPに登録がる原薬をMFに登録する際の注意点は...        4          2235   \n",
       "3                                                NaN        3          2023   \n",
       "\n",
       "   total_cost  \n",
       "0    0.003122  \n",
       "1    0.002938  \n",
       "2    0.003453  \n",
       "3    0.003138  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64310897-179b-4081-aab8-f08a3392a078",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba4c6fa46da4bf09779b6baffce14ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at https://s172-31-2-34p15913.lab-aws-production.deeplearning.ai/ .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eedcef",
   "metadata": {},
   "source": [
    "## Advanced RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a17ea2b",
   "metadata": {},
   "source": [
    "### 1. Sentence Window retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dae4a668-3699-4750-82f7-e53ae1bca3a7",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78f7678f-358d-448d-b153-11ac8e96a7fc",
   "metadata": {
    "height": 149,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import build_sentence_window_index\n",
    "\n",
    "sentence_index = build_sentence_window_index(\n",
    "    document,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"sentence_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72f904c3-9845-4df5-9d2e-e5115160f987",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_sentence_window_query_engine\n",
    "\n",
    "sentence_window_engine = get_sentence_window_query_engine(sentence_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f59e2314-7cac-42f4-a552-9a8e4db641eb",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFは「原薬等登録原簿」の略称です。\n"
     ]
    }
   ],
   "source": [
    "window_response = sentence_window_engine.query(\n",
    "    \"MFとはなんですか。日本語で答えてください。\"\n",
    ")\n",
    "print(str(window_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5c10917-8846-4e73-838d-6232c906a7db",
   "metadata": {
    "height": 115,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tru.reset_database()\n",
    "\n",
    "tru_recorder_sentence_window = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine,\n",
    "    app_id = \"Sentence Window Query Engine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11710e67-aba8-479e-8585-c4c611e2c1d2",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7fdd786ee0b0 is calling an instrumented method <function BaseQueryEngine.query at 0x7fdef3f2eef0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7fdd884af610) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7fdd786ee0b0 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7fdeef34eb90>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7fdd884af610) using this function.\n",
      "A new object of type <class 'llama_index.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> at 0x7fdd786e8910 is calling an instrumented method <function BaseRetriever.retrieve at 0x7fdef3f2e290>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app.retriever based on other object (0x7fdd8847c520) using this function.\n",
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7fdd786ee140 is calling an instrumented method <function CompactAndRefine.get_response at 0x7fdef3969ea0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7fdd884af550) using this function.\n",
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7fdd786ee140 is calling an instrumented method <function Refine.get_response at 0x7fdef2970ee0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7fdd884af550) using this function.\n",
      "A new object of type <class 'llama_index.llm_predictor.base.LLMPredictor'> at 0x7fdd883cf640 is calling an instrumented method <function LLMPredictor.predict at 0x7fdeff63c0d0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer.service_context.llm_predictor based on other object (0x7fdda81b1ec0) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7fdd786ee0b0 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7fdeef34eb90>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7fdd884af610) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFとはなんですか。日本語で答えてください。\n",
      "MFは「原薬等登録原簿」の略称です。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "openai request failed <class 'openai.BadRequestError'>=Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 33963 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Retries remaining=3.\n",
      "openai request failed <class 'openai.BadRequestError'>=Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 33692 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Retries remaining=3.\n",
      "openai request failed <class 'openai.BadRequestError'>=Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 33963 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Retries remaining=2.\n",
      "openai request failed <class 'openai.BadRequestError'>=Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 33692 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Retries remaining=2.\n",
      "openai request failed <class 'openai.BadRequestError'>=Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 33692 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Retries remaining=1.\n",
      "openai request failed <class 'openai.BadRequestError'>=Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 33963 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Retries remaining=1.\n",
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7fdd786ee140 is calling an instrumented method <function Refine.get_response at 0x7fdef2970ee0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7fdd884af550) using this function.\n",
      "openai request failed <class 'openai.BadRequestError'>=Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 33692 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Retries remaining=0.\n",
      "Feedback Function exception caught: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 481, in run\n",
      "    result_and_meta, part_cost = Endpoint.track_all_costs_tally(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 377, in track_all_costs_tally\n",
      "    result, cbs = Endpoint.track_all_costs(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 303, in track_all_costs\n",
      "    return Endpoint._track_costs(thunk, with_endpoints=endpoints)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 480, in _track_costs\n",
      "    result: T = thunk()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 482, in <lambda>\n",
      "    lambda: self.imp(**ins)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/groundedness.py\", line 151, in groundedness_measure_with_cot_reasons\n",
      "    reason = self.groundedness_provider._groundedness_doc_in_out(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/base.py\", line 110, in _groundedness_doc_in_out\n",
      "    return self.endpoint.run_me(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 215, in run_me\n",
      "    raise RuntimeError(\n",
      "RuntimeError: API openai request failed 4 time(s).\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 486, in run\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Evaluation of groundedness_measure_with_cot_reasons failed on inputs: \n",
      "{'source': ' \\n'\n",
      "           '事務連絡 \\n'\n",
      "           '平成２５年４月 １５日 \\n'\n",
      "           ' \\n'\n",
      "           '各都道府県衛生主管部（局）薬務主管課 御中 \\n'\n",
      "       \n",
      "API openai request failed 4 time(s)..\n",
      "\n",
      "openai request failed <class 'openai.BadRequestError'>=Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 33963 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Retries remaining=0.\n",
      "Feedback Function exception caught: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 481, in run\n",
      "    result_and_meta, part_cost = Endpoint.track_all_costs_tally(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 377, in track_all_costs_tally\n",
      "    result, cbs = Endpoint.track_all_costs(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 303, in track_all_costs\n",
      "    return Endpoint._track_costs(thunk, with_endpoints=endpoints)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 480, in _track_costs\n",
      "    result: T = thunk()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 482, in <lambda>\n",
      "    lambda: self.imp(**ins)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/base.py\", line 334, in relevance_with_cot_reasons\n",
      "    return self._extract_score_and_reasons_from_response(system_prompt)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/base.py\", line 142, in _extract_score_and_reasons_from_response\n",
      "    response = self.endpoint.run_me(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 215, in run_me\n",
      "    raise RuntimeError(\n",
      "RuntimeError: API openai request failed 4 time(s).\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 486, in run\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Evaluation of relevance_with_cot_reasons failed on inputs: \n",
      "{'prompt': 'MFとはなんですか。日本語で答えてください。',\n",
      " 'response': ' \\n'\n",
      "             '事務連絡 \\n'\n",
      "             '平成２５年４月 １５日 \\n'\n",
      "             ' \\n'\n",
      "\n",
      "API openai request failed 4 time(s)..\n",
      "\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7fdd786ee0b0 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7fdeef34eb90>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7fdd884af610) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFの申請書類はなんですか。日本語で答えてください。\n",
      "MFの申請書類は、医薬品に関するMF登録に使用する電子的な様式についての記載事項と、登録申請書に添付する資料（登録データ）に関する様式があります。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7fdd786ee140 is calling an instrumented method <function Refine.get_response at 0x7fdef2970ee0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7fdd884af550) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7fdd786ee0b0 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7fdeef34eb90>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7fdd884af610) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USPに登録がる原薬をMFに登録する際の注意点はなんですか。日本語で答えてください。\n",
      "原薬をMFに登録する際の注意点は、製造方法、製造工程管理、品質管理試験、規格及び試験方法、安定性試験、非臨床試験（主として新添加剤）に関する情報を登録することです。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7fdd786ee140 is calling an instrumented method <function Refine.get_response at 0x7fdef2970ee0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7fdd884af550) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFの仕組みを教えてください。日本語で答えてください。\n",
      "MFは、製造所の名称や製造方法、品質管理試験、規格及び試験方法、安定性試験などの情報を登録することができるシステムです。また、製造工程中の細菌、真菌、ウイルスの不活化／除去処理方法や規格及び試験方法に関する情報も含まれます。MFを利用する際には、登録者と利用者間で情報の取り扱いについて十分な協議が必要とされています.\n"
     ]
    }
   ],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder_sentence_window as recording:\n",
    "        response = sentence_window_engine.query(question)\n",
    "        print(question)\n",
    "        print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "869d1e55-729b-45f2-a0f9-773c49d4616f",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence Window Query Engine</th>\n",
       "      <td>0.325</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.75</td>\n",
       "      <td>0.055591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Groundedness  Context Relevance  \\\n",
       "app_id                                                          \n",
       "Sentence Window Query Engine         0.325                1.0   \n",
       "\n",
       "                              Answer Relevance  latency  total_cost  \n",
       "app_id                                                               \n",
       "Sentence Window Query Engine               1.0    33.75    0.055591  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b92d0f2-2e80-48d5-92af-b3655eb03ea2",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n",
      "Dashboard already running at path: https://s172-31-2-34p15913.lab-aws-production.deeplearning.ai/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "openai request failed <class 'openai.BadRequestError'>=Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 33969 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Retries remaining=3.\n",
      "openai request failed <class 'openai.BadRequestError'>=Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 33842 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Retries remaining=3.\n",
      "openai request failed <class 'openai.BadRequestError'>=Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 33969 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Retries remaining=2.\n",
      "openai request failed <class 'openai.BadRequestError'>=Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 33842 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Retries remaining=2.\n",
      "openai request failed <class 'openai.BadRequestError'>=Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 33969 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Retries remaining=1.\n",
      "openai request failed <class 'openai.BadRequestError'>=Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 33842 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Retries remaining=1.\n",
      "openai request failed <class 'openai.BadRequestError'>=Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 33969 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Retries remaining=0.\n",
      "Feedback Function exception caught: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 481, in run\n",
      "    result_and_meta, part_cost = Endpoint.track_all_costs_tally(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 377, in track_all_costs_tally\n",
      "    result, cbs = Endpoint.track_all_costs(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 303, in track_all_costs\n",
      "    return Endpoint._track_costs(thunk, with_endpoints=endpoints)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 480, in _track_costs\n",
      "    result: T = thunk()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 482, in <lambda>\n",
      "    lambda: self.imp(**ins)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/base.py\", line 334, in relevance_with_cot_reasons\n",
      "    return self._extract_score_and_reasons_from_response(system_prompt)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/base.py\", line 142, in _extract_score_and_reasons_from_response\n",
      "    response = self.endpoint.run_me(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 215, in run_me\n",
      "    raise RuntimeError(\n",
      "RuntimeError: API openai request failed 4 time(s).\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 486, in run\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Evaluation of relevance_with_cot_reasons failed on inputs: \n",
      "{'prompt': 'MFの仕組みを教えてください。日本語で答えてください。',\n",
      " 'response': ' \\n'\n",
      "             '事務連絡 \\n'\n",
      "             '平成２５年４月 １５日 \\n'\n",
      "             '\n",
      "API openai request failed 4 time(s)..\n",
      "\n",
      "openai request failed <class 'openai.BadRequestError'>=Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 33842 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Retries remaining=0.\n",
      "Feedback Function exception caught: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 481, in run\n",
      "    result_and_meta, part_cost = Endpoint.track_all_costs_tally(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 377, in track_all_costs_tally\n",
      "    result, cbs = Endpoint.track_all_costs(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 303, in track_all_costs\n",
      "    return Endpoint._track_costs(thunk, with_endpoints=endpoints)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 480, in _track_costs\n",
      "    result: T = thunk()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 482, in <lambda>\n",
      "    lambda: self.imp(**ins)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/groundedness.py\", line 151, in groundedness_measure_with_cot_reasons\n",
      "    reason = self.groundedness_provider._groundedness_doc_in_out(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/base.py\", line 110, in _groundedness_doc_in_out\n",
      "    return self.endpoint.run_me(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 215, in run_me\n",
      "    raise RuntimeError(\n",
      "RuntimeError: API openai request failed 4 time(s).\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 486, in run\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Evaluation of groundedness_measure_with_cot_reasons failed on inputs: \n",
      "{'source': ' \\n'\n",
      "           '事務連絡 \\n'\n",
      "           '平成２５年４月 １５日 \\n'\n",
      "           ' \\n'\n",
      "           '各都道府県衛生主管部（局）薬務主管課 御中 \\n'\n",
      "       \n",
      "API openai request failed 4 time(s)..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92e2c55",
   "metadata": {},
   "source": [
    "### 2. Auto-merging retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "558c639b-31eb-4c34-b6c4-fe6ae5717733",
   "metadata": {
    "height": 149,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import build_automerging_index\n",
    "\n",
    "automerging_index = build_automerging_index(\n",
    "    documents,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"merging_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b32265f2-0247-42df-9abe-97d52f69edcf",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_automerging_query_engine\n",
    "\n",
    "automerging_query_engine = get_automerging_query_engine(\n",
    "    automerging_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "918ed568-220e-4c7c-aa60-cfa58ef1fcbd",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 89e4d1be-5eae-4f57-92aa-f042b7aff6d5.\n",
      "> Parent node text: 21http://www.pmda.go.jp/int -activities/int -harmony/ich/0035.htmlICHM4Q第２部（モジュール２）：品質に関する概括資料、第\n",
      "...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: f6a451a8-fd4e-456c-9e98-8992ac433703.\n",
      "> Parent node text: 21http://www.pmda.go.jp/int -activities/int -harmony/ich/0035.htmlICHM4Q第２部（モジュール２）：品質に関する概括資料、第\n",
      "...\n",
      "\n",
      "You can build a portfolio of AI projects by focusing on various aspects such as project structure, general characteristics, manufacturing details, manufacturers involved, manufacturing methods, process control, and related substances. It is important to follow the specified format and guidelines provided for creating the necessary documentation for each project.\n"
     ]
    }
   ],
   "source": [
    "auto_merging_response = automerging_query_engine.query(\n",
    "    \"How do I build a portfolio of AI projects?\"\n",
    ")\n",
    "print(str(auto_merging_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db4f18a9-7b8a-4ae2-ab11-3a6a941a5afc",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tru.reset_database()\n",
    "\n",
    "tru_recorder_automerging = get_prebuilt_trulens_recorder(automerging_query_engine,\n",
    "                                                         app_id=\"Automerging Query Engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99cc2cfe-7096-4fa0-aa72-094bebac35a3",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFとはなんですか。日本語で答えてください。\n",
      "MFは「薬事法」で規定された医薬品の製造において使用される原薬、中間体、製剤原料の品質及び安全性を確認するための登録制度です。\n",
      "MFの申請書類はなんですか。日本語で答えてください。\n",
      "MFの申請書類は、登録申請書と登録データです。\n",
      "USPに登録がる原薬をMFに登録する際の注意点はなんですか。日本語で答えてください。\n",
      "原薬、中間体及び製剤原料（バルクのうち特殊な剤型等）については、品質及び安全性が従来の規格及び試験方法においても確立されているものと考えられており、当面、MFを利用することは差し控えられたい。\n",
      "MFの仕組みを教えてください。日本語で答えてください。\n",
      "MFは、日本薬局方に収載された医薬品の承認審査において使用される登録制度です。人や動物に共通に使用される医薬品の場合、MFを利用する際は、機構にMF登録を行う必要があります。MF登録番号が付与され、その番号を用いて医薬品や医療機器の取扱いに関する情報が管理されます。\n"
     ]
    }
   ],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder_automerging as recording:\n",
    "        response = automerging_query_engine.query(question)\n",
    "        print(question)\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5404dec1-60ca-42fa-ac13-793a5423aa64",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Automerging Query Engine</th>\n",
       "      <td>0.838889</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Groundedness  Context Relevance  Answer Relevance  \\\n",
       "app_id                                                                        \n",
       "Automerging Query Engine      0.838889                0.6               1.0   \n",
       "\n",
       "                          latency  total_cost  \n",
       "app_id                                         \n",
       "Automerging Query Engine      4.0    0.000732  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0f545d41-0d98-446f-8214-8b59bef08d6c",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n",
      "Dashboard already running at path: https://s172-31-2-34p15913.lab-aws-production.deeplearning.ai/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
