{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PfDOv8eQAbVQ"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m userdata\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m userdata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('openai')\n",
        "qdrant_key = userdata.get('qdrant')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9ZwEbi6EIbgi",
        "outputId": "47c4b67e-5b89-4302-9651-ed4a53105dda"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index-vector-stores-qdrant llama-index-readers-file llama-index-embeddings-fastembed\n",
        "!pip install qdrant_client fastembed\n",
        "!pip install llama-index-llms-openai\n",
        "!pip install llama-index-extractors-entity\n",
        "!pip install llama-index llama-index-readers-web\n",
        "!pip install llama-index-embeddings-openai\n",
        "\n",
        "!pip install html2text\n",
        "!pip install  tenacity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "wZWW3ZV-C5oO"
      },
      "outputs": [],
      "source": [
        "from qdrant_client import QdrantClient\n",
        "\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.schema import MetadataMode\n",
        "from llama_index.core import (\n",
        "    GPTVectorStoreIndex,\n",
        "    VectorStoreIndex,\n",
        "    SimpleDirectoryReader,\n",
        "    ServiceContext,\n",
        "    StorageContext,\n",
        "    load_index_from_storage,\n",
        "    Settings,\n",
        "#    ChatPromptTemplate,\n",
        "    PromptTemplate,\n",
        ")\n",
        "from llama_index.core.callbacks import(\n",
        "    CallbackManager, LlamaDebugHandler, CBEventType,\n",
        ")\n",
        "from llama_index.core.extractors import (\n",
        "    SummaryExtractor,\n",
        "    QuestionsAnsweredExtractor,\n",
        "    TitleExtractor,\n",
        "    KeywordExtractor,\n",
        "    BaseExtractor,\n",
        ")\n",
        "#from llama_index.extractors.entity import EntityExtractor\n",
        "from llama_index.core.node_parser import TokenTextSplitter, SentenceSplitter\n",
        "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core.ingestion import IngestionPipeline, IngestionCache\n",
        "\n",
        "from tenacity import ( retry, stop_after_attempt,  wait_random_exponential,)  # for exponential backoff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezYMjqPRDA9N",
        "outputId": "76815a1d-76e0-4775-a853-aeb17efc78e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "collections=[CollectionDescription(name='test'), CollectionDescription(name='MFdatabase')]\n"
          ]
        }
      ],
      "source": [
        "qdrant_client = QdrantClient(\n",
        "    url=\"https://c5c4eea7-3717-4878-a79e-25946e0c048d.us-east4-0.gcp.cloud.qdrant.io:6333\",\n",
        "    api_key=qdrant_key,\n",
        ")\n",
        "\n",
        "print(qdrant_client.get_collections())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "TSiVpVuBILqP"
      },
      "outputs": [],
      "source": [
        "vector_store = QdrantVectorStore(client=qdrant_client, collection_name=\"MFdatabase\")\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "MDaCi6CA-lBX"
      },
      "outputs": [],
      "source": [
        "pipeline = IngestionPipeline(\n",
        "    transformations=[\n",
        "        TokenTextSplitter(separator=\"。 \", chunk_size=512, chunk_overlap=128),\n",
        "        #SentenceSplitter(chunk_size=25, chunk_overlap=0),\n",
        "        #TitleExtractor(),\n",
        "        OpenAIEmbedding(),\n",
        "    ],\n",
        "    vector_store=vector_store,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "bGTjAM9fEglj"
      },
      "outputs": [],
      "source": [
        "#古いデータを消す\n",
        "!rm data/*.pdf\n",
        "!rm data/*.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3joeuhSEmdf"
      },
      "source": [
        "新しいDocumentをDataフォルダにいれIngestion　Pipelineを実行　Qdrant　DBに格納"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DK4o-7MdIG5c",
        "outputId": "177a53c0-f45d-4ec9-a39f-840bb912a153"
      },
      "outputs": [],
      "source": [
        "# load documents\n",
        "documents = SimpleDirectoryReader(\"./data\").load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Gs7Z_ApMt0K"
      },
      "outputs": [],
      "source": [
        "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
        "def run_pipeline(documents):\n",
        "  pipeline.run(documents=documents)\n",
        "  return\n",
        "\n",
        "run_pipeline(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9invopzU-k46",
        "outputId": "dedb13b6-0349-4ff0-b822-694e0c75883c"
      },
      "outputs": [],
      "source": [
        "#pipeline.run(documents=documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB8-CGfQExUC"
      },
      "source": [
        "格納したDBよりINDEXにダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "6edVi2AcX3Ie"
      },
      "outputs": [],
      "source": [
        "index = VectorStoreIndex.from_vector_store(vector_store=vector_store,)\n",
        "query_engine = index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iftD28lnECfS",
        "outputId": "ad7ffbfe-67ad-4ee5-ac79-076f3d5e4a28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "残留溶媒の管理は、それぞれの溶媒の濃度限度値毎に管理されます。残留溶媒については、質量管理であり、製造中に生成される溶媒も対象となります。特定の溶媒がPDE値を超える場合、一変申請が必要であり、他の溶媒が軽微変更届出の対象であっても、一変申請が必要です。\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"残留溶媒について教えてください。日本語で回答してください\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FncLlUXEV5C"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJQ-QCwvEV2Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mkW75ZJEVzl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqE_tpIwEVwo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ljuqCgaEVuB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4G2T6klgEVq-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "isrDWHlM-lF6"
      },
      "outputs": [],
      "source": [
        "# text_splitter = TokenTextSplitter(\n",
        "#         separator=\"。 \", chunk_size=512, chunk_overlap=128)\n",
        "\n",
        "# extractors = [\n",
        "#         #TitleExtractor(nodes=1, llm=llm), #5\n",
        "#         #QuestionsAnsweredExtractor(questions=1, llm=llm), #3\n",
        "#         # EntityExtractor(prediction_threshold=0.5),\n",
        "#         # SummaryExtractor(summaries=[\"prev\", \"self\"], llm=llm),\n",
        "#         # KeywordExtractor(keywords=10, llm=llm),\n",
        "#         # CustomExtractor()\n",
        "#     ]\n",
        "\n",
        "# transformations = extractors + [text_splitter]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tYlkJ1SEDEC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
